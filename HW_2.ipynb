{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970df3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Toolboxs'''\n",
    "import re\n",
    "import cv2\n",
    "import os\n",
    "from os.path import join\n",
    "import random\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import partial\n",
    "from sklearn.model_selection import train_test_split\n",
    "'''Tensorflow'''\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import callbacks as cb\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Input, Lambda, Dense, Dropout, Conv2D, MaxPooling2D, Flatten,Activation,BatchNormalization\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input,EfficientNetB0\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices(device_type='GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth( device=gpu, enable=True)\n",
    "if len(gpus)>1:\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = f\"{len(gpus)-1}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687f0449",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "W,H,CH = 64,64,1\n",
    "\n",
    "def load_img(path, width = W, hight=H):\n",
    "    img=cv2.imread(path.numpy().decode())[...,0].astype(np.float32)/255.\n",
    "#     img = read_pgm(path.numpy().decode()).astype(np.float32)/255.\n",
    "    min_of_shape = np.min(img.shape[:2])\n",
    "    oh = (img.shape[0] - min_of_shape) // 2\n",
    "    ow = (img.shape[1] - min_of_shape) // 2\n",
    "    center_square = np.array([width,hight])// 2\n",
    "    new_size=(width,hight)\n",
    "    \n",
    "    # cropping + resize\n",
    "    img = img[oh:oh + min_of_shape, ow:ow + min_of_shape]\n",
    "    img=np.expand_dims(cv2.resize(img, new_size),-1)\n",
    "    return tf.constant(img-0.5)\n",
    "SUFFIX='.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2fcca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "WAYS = 3\n",
    "SHOTS=5\n",
    "QUERIES=WAYS*1\n",
    "BATCH_SIZE=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5672b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2021)\n",
    "tf.random.set_seed(2021)\n",
    "DATA_ROOT=\"./kaggle_fungi/source\"\n",
    "# DATA_ROOT=join(\"..\",\"..\",\"data\")\n",
    "# DATA_ROOT=\"I:\\AIA Small Data\\datasets\"\n",
    "all_classes = glob(join(DATA_ROOT,\"source\",\"*\"))\n",
    "source_classes,target_classes=train_test_split(all_classes,test_size=0.2)\n",
    "sorce_len=len(source_classes)\n",
    "target_len=len(target_classes)\n",
    "print(f\"total {len(all_classes)} classes=source {sorce_len} + target {target_len} classes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af235efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## exclude classes with too few examples\n",
    "source_classes=[sdir for sdir in source_classes if len(glob(join(sdir,'*'+SUFFIX)))>SHOTS+QUERIES]\n",
    "\n",
    "sorce_len=len(source_classes)\n",
    "print(f\"source {sorce_len} + target {target_len} classes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8399caa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(target_classes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91ccd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Mapping function for loading'''\n",
    "map_fun=lambda string: tf.py_function(func=load_img,inp=[string], Tout=tf.float32)\n",
    "'''Source set中每個人都有一個tf Dataset loader'''\n",
    "source_sup_sub = [\n",
    "    tf.data.Dataset.list_files(glob(join(sc,'*'+SUFFIX)), shuffle=True)\n",
    "    .map(map_fun).cache()\n",
    "    for sc in source_classes\n",
    "]\n",
    "source_q_sub = [\n",
    "    tf.data.Dataset.list_files(glob(join(sc,'*'+SUFFIX)), shuffle=True)\n",
    "    .map(map_fun).cache()\n",
    "    for sc in source_classes\n",
    "]\n",
    "'''Target set中每個人都有一個tf Dataset loader'''\n",
    "target_sup_sub = [\n",
    "    tf.data.Dataset.list_files(glob(join(sc,'*'+SUFFIX)), shuffle=True)\n",
    "    .map(map_fun).cache()\n",
    "    for sc in target_classes\n",
    "]\n",
    "target_q_sub = [\n",
    "    tf.data.Dataset.list_files(glob(join(sc,'*'+SUFFIX)), shuffle=True)\n",
    "    .map(map_fun).cache()\n",
    "    for sc in target_classes\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a69e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for sub in source_sup_sub :\n",
    "    for x in iter(sub.batch(10)):\n",
    "        pass\n",
    "for sub in source_q_sub :\n",
    "    for x in iter(sub.batch(10)):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a3643c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for sub in target_sup_sub :\n",
    "    for x in iter(sub.batch(10)):\n",
    "        pass\n",
    "for sub in target_q_sub :\n",
    "    for x in iter(sub.batch(10)):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5d9c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen(sup_sub,query_sub):\n",
    "    '''先決定好順序'''\n",
    "    order=np.random.permutation(len(sup_sub))  \n",
    "    '''For each task'''\n",
    "    for tasks in range(len(sup_sub)//WAYS):\n",
    "        '''從已決定好的順序拉出WAY個人'''\n",
    "        picked=[sup_sub[tt] for tt in order[WAYS*tasks:WAYS*(tasks+1)]]\n",
    "        picked_q=[query_sub[tt] for tt in order[WAYS*tasks:WAYS*(tasks+1)]]\n",
    "        '''support每個人各有SHOTS張照片'''\n",
    "        support = tf.concat(\n",
    "            [\n",
    "                next(\n",
    "                    iter(\n",
    "                        sub.batch(SHOTS)\n",
    "                    )\n",
    "                    ) for sub in picked\n",
    "            ]\n",
    "            , axis=0)\n",
    "        '''query挑WAY人中的QUERY張，這邊是設定每張屬於不同人，順序不固定'''\n",
    "        idxs=np.random.choice(range(WAYS), size=QUERIES, replace=False)\n",
    "        query = tf.concat(\n",
    "            [\n",
    "                next(\n",
    "                    iter(\n",
    "                        picked_q[idx].batch(1)\n",
    "                    )\n",
    "                    ) for idx in idxs\n",
    "            ]\n",
    "            , axis=0)\n",
    "        '''輸出的時候把support跟query接在一起'''\n",
    "        yield tf.concat([support, query], axis=0), tf.stack([keras.utils.to_categorical(idx,num_classes=WAYS) for idx in idxs], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e38f03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107d11eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLUT=16\n",
    "data_source = tf.data.Dataset.from_generator(partial(gen,source_sup_sub,source_q_sub),\n",
    "                                    output_types=(tf.float32,tf.float32),\n",
    "                                    output_shapes=((WAYS*SHOTS+QUERIES,W,H,CH),(QUERIES,WAYS))\n",
    "                                            ).repeat(MLUT).shuffle(buffer_size=999).cache().batch(BATCH_SIZE).prefetch(MLUT)\n",
    "data_target = tf.data.Dataset.from_generator(partial(gen,target_sup_sub,target_q_sub),\n",
    "                                    output_types=(tf.float32,tf.float32),\n",
    "                                    output_shapes=((WAYS*SHOTS+QUERIES,W,H,CH),(QUERIES,WAYS))\n",
    "                                            ).repeat(MLUT*4).batch(BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20b9c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding function\n",
    "def conv_net(input_shape):\n",
    "    convnet = Sequential()\n",
    "    for i in range(3):\n",
    "        convnet.add(Conv2D(64,(3,3),padding='valid',input_shape=input_shape))\n",
    "        convnet.add(BatchNormalization())\n",
    "        convnet.add(Activation('relu'))\n",
    "        convnet.add(MaxPooling2D())\n",
    "    return convnet\n",
    "def build_relation_network(input_shape):\n",
    "    seq = Sequential()\n",
    "    #layer1\n",
    "    seq.add(Conv2D(64, kernel_size=3, input_shape=input_shape,\n",
    "                           padding=\"valid\",activation='relu'))\n",
    "    seq.add(BatchNormalization()) \n",
    "    seq.add(MaxPooling2D(pool_size=(2, 2)))  \n",
    "#     seq.add(Dropout(.1))\n",
    "    \n",
    "    seq.add(Flatten())\n",
    "    seq.add(Dense(8, activation='relu'))\n",
    "#     seq.add(Dropout(0.1))\n",
    "    seq.add(Dense(1, activation=None))\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245a9f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dim = (W,H,CH)\n",
    "print(base_dim)\n",
    "base_network = conv_net(base_dim)\n",
    "# Query feature\n",
    "x_in=Input(shape=(WAYS*SHOTS+QUERIES,W,H,CH))\n",
    "latent_s=[base_network(x_in[:,ii]) for ii in range(WAYS*SHOTS)]\n",
    "latent_q=[base_network(x_in[:,WAYS*SHOTS+ii]) for ii in range(QUERIES)]\n",
    "\n",
    "relation_net=build_relation_network((latent_q[0].shape[-3],latent_q[0].shape[-2],latent_q[0].shape[-1]*2))\n",
    "print(latent_q[0].shape[-3],latent_q[0].shape[-2],latent_q[0].shape[-1]*2)\n",
    "y=[]\n",
    "for q in latent_q:\n",
    "    relation_score=[]\n",
    "    for ww in range(WAYS):\n",
    "        relation=[relation_net(tf.concat([q,s],-1)) for s in latent_s[ww*SHOTS:(ww+1)*SHOTS]]\n",
    "        relation_score.append(tf.reduce_mean(tf.concat(relation,-1),-1,keepdims=True))\n",
    "        \n",
    "    y.append(tf.nn.softmax(tf.concat(relation_score,-1),-1))\n",
    "pred=tf.stack(y,1)\n",
    "\n",
    "model = Model(inputs=x_in, outputs=pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a153e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=0.001\n",
    "reduce_lr = cb.ReduceLROnPlateau(monitor='val_loss', factor=0.1,patience=6, min_lr=1e-8, verbose=1)\n",
    "tensorboard = cb.TensorBoard(log_dir=\"tf_relation_logs\")\n",
    "earlystop=cb.EarlyStopping(monitor='val_loss',patience=10,restore_best_weights=True, verbose=1)\n",
    "opt = tf.keras.optimizers.Adam(lr=lr)\n",
    "model.compile(loss=CategoricalCrossentropy(), optimizer=opt, metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74742cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS=100\n",
    "# %%time\n",
    "try:\n",
    "    model.fit(data_source,\n",
    "              epochs=EPOCHS, verbose=1,workers=4,\n",
    "              callbacks=[reduce_lr,earlystop, tensorboard],\n",
    "              validation_data=data_source)\n",
    "except KeyboardInterrupt:\n",
    "    print(\"KeyboardInterrupt\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441a8b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(data_target, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40abdd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tasks in range(len(test_query)):\n",
    "    picked =[test_support[tt] for tt in range(3*tasks,3*(tasks+1))]\n",
    "    picked_q=[test_query[tt] for tt in range(3*tasks,tasks+1)]\n",
    "    imgs_t =  tf.concat(\n",
    "        [\n",
    "        next(\n",
    "            iter(\n",
    "                sub.batch(SHOTS+1)) #.prefetch(tf.data.AUTOTUNE))\n",
    "            )\n",
    "            for sub in picked\n",
    "        ]\n",
    "        , axis=0)\n",
    "    idxs=np.random.choice(range(WAYS), size=QUERIES, replace=False)\n",
    "    imgs_q =  tf.concat(\n",
    "        [\n",
    "    next(\n",
    "        iter(\n",
    "            sub.batch(SHOTS)) #.prefetch(tf.data.AUTOTUNE))\n",
    "        )\n",
    "        for sub in picked_q\n",
    "        ]\n",
    "        , axis=0)\n",
    "    print(imgs_q.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d40a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_test(sup_sub,query_sub):\n",
    "    '''先決定好順序'''\n",
    "#     for tasks in range(len(test_query)):\n",
    "#         picked =[test_support[tt] for tt in range(3*tasks,3*(tasks+1))]\n",
    "#         picked_q=[test_query[tt] for tt in range(3*tasks,tasks+1)]\n",
    "#         imgs_t =  tf.concat(\n",
    "#             [\n",
    "#             next(\n",
    "#                 iter(\n",
    "#                     sub.batch(SHOTS+1)) #.prefetch(tf.data.AUTOTUNE))\n",
    "#                 )\n",
    "#                 for sub in picked\n",
    "#             ]\n",
    "#             , axis=0)\n",
    "#         idxs=np.random.choice(range(WAYS), size=QUERIES, replace=False)\n",
    "#         imgs_q =  tf.concat(\n",
    "#             [\n",
    "#         next(\n",
    "#             iter(\n",
    "#                 sub.batch(SHOTS)) #.prefetch(tf.data.AUTOTUNE))\n",
    "#             )\n",
    "#             for sub in picked_q\n",
    "#             ]\n",
    "#             , axis=0)\n",
    "#         yield tf.concat([imgs_t, imgs_q], axis=0)\n",
    "\n",
    "    order=np.random.permutation(len(sup_sub))  \n",
    "#     '''For each task'''\n",
    "    for tasks in range(len(sup_sub)//WAYS):\n",
    "        '''從已決定好的順序拉出WAY個人'''\n",
    "        picked=[sup_sub[tt] for tt in order[WAYS*tasks:WAYS*(tasks+1)]]\n",
    "        picked_q=[query_sub[tt] for tt in order[WAYS*tasks:WAYS*(tasks+1)]]\n",
    "        '''support每個人各有SHOTS張照片'''\n",
    "        support = tf.concat(\n",
    "            [\n",
    "                next(\n",
    "                    iter(\n",
    "                        sub.batch(SHOTS)\n",
    "                    )\n",
    "                    ) for sub in picked\n",
    "            ]\n",
    "            , axis=0)\n",
    "        '''query挑WAY人中的QUERY張，這邊是設定每張屬於不同人，順序不固定'''\n",
    "        idxs=np.random.choice(range(WAYS), size=QUERIES, replace=False)\n",
    "        \n",
    "        query = tf.concat(\n",
    "            [\n",
    "                next(\n",
    "                    iter(\n",
    "                        sub.batch(SHOTS)\n",
    "                       \n",
    "                    )\n",
    "                    ) for sub in picked_q\n",
    "            ]\n",
    "            , axis=0)\n",
    "        '''輸出的時候把support跟query接在一起'''\n",
    "    yield tf.concat([imgs_t, imgs_q], axis=0)#, tf.stack([keras.utils.to_categorical(idx,num_classes=WAYS) for idx in idxs], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a85afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = tf.data.Dataset.from_generator(partial(gen_test,test_support,test_query),\n",
    "                        output_types=(tf.float32,tf.float32),\n",
    "                        output_shapes=((WAYS*SHOTS+QUERIES,W,H,CH),(QUERIES,WAYS))\n",
    "                                ).repeat(MLUT*4).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eec2627",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # 預測結果\n",
    "all_result = []\n",
    "for batch in data_test.batch(50):\n",
    "    pre = model.predict(batch)\n",
    "    print(pre.shape)\n",
    "    for i in pre:\n",
    "        all_result.extend(np.argmax(i, axis=1))\n",
    "\n",
    "df = pd.read_csv('SampleSubmission2.csv')\n",
    "df['ans'] = all_result\n",
    "df.to_csv('Submission2.csv', index=False)\n",
    "print('Done.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ddd039",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# read kaggle test1.csv file row by row\n",
    "ans = pd.DataFrame(columns=['filename', 'ans'])\n",
    "import csv\n",
    "file_name =[]\n",
    "support_list = []\n",
    "\n",
    "MLUT=16\n",
    "with open (r'C:/Users/2103099/Documents/kaggle_fungi/test2.csv',newline='') as csvfile:\n",
    "    rows = csv.reader(csvfile)\n",
    "    print(rows)\n",
    "\n",
    "    for i, row in enumerate(rows):\n",
    "#         print(i)\n",
    "#        \n",
    "        if i == 0:\n",
    "            continue\n",
    "        \n",
    "        # restore model weights at the begining of adaptation\n",
    "       # model.set_weights(w)\n",
    "# abs\n",
    "        imgs, labels = (row[0],row[1:4])\n",
    "        hw_file_name = row[0]\n",
    "       \n",
    "        hw_support_list = row[1:4]\n",
    "#         support_list.append(hw_support_list)\n",
    "        test_data_path = [\"C:/Users/2103099/Documents/kaggle_fungi/target_s/target_s/\"+i+\"/\" for i in hw_support_list]\n",
    "        support_list.append(test_data_path)\n",
    "        test_img = \"C:/Users/2103099/Documents/kaggle_fungi/target_q/target_q/\"+hw_file_name\n",
    "        file_name.append(test_img)\n",
    "        \n",
    "        \n",
    "        test_support = [\n",
    "        tf.data.Dataset.list_files(os.path.join(sc,'*.JPG'), shuffle=True)\n",
    "        .map(map_fun)for sc in test_data_path]\n",
    "        \n",
    "#         print(f'len(test_support): {len(test_support)}')\n",
    "        \n",
    "        test_query = [\n",
    "        tf.data.Dataset.list_files(test_img, shuffle=False)\n",
    "        .map(map_fun)\n",
    "        #for sc in test_img\n",
    "        ]\n",
    "#         print(f'len(test_query): {len(test_query)}')\n",
    "     \n",
    "\n",
    "\n",
    "        \n",
    "        # # 預測結果\n",
    "        all_result = []\n",
    "        for batch in data_test.batch(10):\n",
    "            print(batch)\n",
    "            pre = model.predict(batch)\n",
    "            print(pre.shape)\n",
    "            for i in pre:\n",
    "                all_result.extend(np.argmax(i, axis=1))\n",
    "            print(all_result)\n",
    "        df = pd.read_csv('SampleSubmission2.csv')\n",
    "        df['ans'] = all_result\n",
    "        df.to_csv('Submission2.csv', index=False)\n",
    "        print('Done.')\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "#         for task in range(len(test_support)):\n",
    "#             print(f'test: {task}')\n",
    "#     # 每一筆test 有 三個類別\n",
    "#             print(f'test: {task}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f43c3cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dcc0ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(file_name[0])\n",
    "# ./kaggle_fungi/source\\source\\14155_Ganoderma_adspersum\n",
    "# print(support_list[0])\n",
    "# for sc in support_list:\n",
    "#     print(sc)\n",
    "#     for i in sc:\n",
    "test_ans = [ sc for sc in file_name ]\n",
    "print(len(test_ans))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51eb63aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Mapping function for loading'''\n",
    "map_fun=lambda string: tf.py_function(func=load_img,inp=[string], Tout=tf.float32)\n",
    "\n",
    "'''Test set中每個人都有一個tf Dataset loader'''\n",
    "\n",
    "test_support = [\n",
    "tf.data.Dataset.list_files(os.path.join(i,'*.JPG'), shuffle=True)\n",
    ".map(map_fun) for i in sc for sc in support_list]\n",
    "\n",
    "# test_ans = [[i  for i in sc] for sc in support_list]\n",
    "\n",
    "test_query = [\n",
    "    tf.data.Dataset.list_files(sc, shuffle=False)\n",
    "    .map(map_fun) for sc in file_name\n",
    "]\n",
    "\n",
    "# print(test_support)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb6b07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'len(test_support): {len(test_support)}')\n",
    "\n",
    "print(f'len(test_query): {len(test_query)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b872011",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tasks in range(len(test_query)):\n",
    "    picked=[test_support[tt] for tt in range(3*tasks,3*(tasks+1))]\n",
    "    imgs_t =  tf.concat(\n",
    "            [\n",
    "                next(\n",
    "                    iter(\n",
    "                        sub.batch(SHOTS+1)) #.prefetch(tf.data.AUTOTUNE))\n",
    "                    )\n",
    "                    for sub in picked\n",
    "            ]\n",
    "            , axis=0)\n",
    "#     print(imgs_t)\n",
    "    \n",
    "    picked_q=[test_query[tt] for tt in range(3*tasks,tasks+1)]\n",
    "    imgs_q =  tf.concat(\n",
    "        [\n",
    "            next(\n",
    "                iter(\n",
    "                    sub.batch(SHOTS)) #.prefetch(tf.data.AUTOTUNE))\n",
    "                )\n",
    "                for sub in picked_q\n",
    "        ]\n",
    "        , axis=0)\n",
    "#     print(imgs_q.shape)\n",
    "#     idxs=np.random.choice(range(3), size=1, replace=False)\n",
    "#     imgs_q = tf.concat(\n",
    "#         [\n",
    "#             next(\n",
    "#                 iter(\n",
    "#                     picked_q[idx].batch(1)\n",
    "#                 )\n",
    "#                 ) for idx in idxs\n",
    "#         ]\n",
    "#         , axis=0)\n",
    "#     '''輸出的時候把support跟query接在一起'''\n",
    "#     tf_con = tf.concat([imgs_s, imgs_q], axis=0)\n",
    "#     yield tf.concat([imgs_s, imgs_q], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c426f009",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen2(test_support,test_query):\n",
    "    '''先決定好順序'''\n",
    "    order=np.random.permutation(len(sup_sub))  \n",
    "#     '''For each task'''\n",
    "    for tasks in range(len(sup_sub)//WAYS):\n",
    "        '''從已決定好的順序拉出WAY個人'''\n",
    "        picked=[sup_sub[tt] for tt in order[WAYS*tasks:WAYS*(tasks+1)]]\n",
    "        picked_q=[query_sub[tt] for tt in order[WAYS*tasks:WAYS*(tasks+1)]]\n",
    "        '''support每個人各有SHOTS張照片'''\n",
    "        support = tf.concat(\n",
    "            [\n",
    "                next(\n",
    "                    iter(\n",
    "                        sub.batch(SHOTS)\n",
    "                    )\n",
    "                    ) for sub in picked\n",
    "            ]\n",
    "            , axis=0)\n",
    "        '''query挑WAY人中的QUERY張，這邊是設定每張屬於不同人，順序不固定'''\n",
    "        idxs=np.random.choice(range(WAYS), size=QUERIES, replace=False)\n",
    "        query = tf.concat(\n",
    "            [\n",
    "                next(\n",
    "                    iter(\n",
    "                        picked_q[idx].batch(1)\n",
    "                    )\n",
    "                    ) for idx in idxs\n",
    "            ]\n",
    "            , axis=0)\n",
    "        '''輸出的時候把support跟query接在一起'''\n",
    "        yield tf.concat([support, query], axis=0), tf.stack([keras.utils.to_categorical(idx,num_classes=WAYS) for idx in idxs], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c27e9b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd6b252",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e709d5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "        \n",
    "        test_support = [\n",
    "        tf.data.Dataset.list_files(os.path.join(sc,'*.JPG'), shuffle=True)\n",
    "        .map(map_fun)\n",
    "        for sc in test_data_path]\n",
    "        print(f'len(test_support): {len(test_support)}')\n",
    "        \n",
    "        test_query = [\n",
    "        tf.data.Dataset.list_files(test_img, shuffle=False)\n",
    "        .map(map_fun)\n",
    "        #for sc in test_img\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab8cc9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
