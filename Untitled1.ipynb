{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd795d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "import cv2\n",
    "import os\n",
    "from os.path import join\n",
    "import random\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import partial\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import callbacks as cb\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Input, Lambda, Dense, Dropout, Conv2D, MaxPooling2D, Flatten, Activation, \\\n",
    "    BatchNormalization\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input, EfficientNetB0\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices(device_type='GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(device=gpu, enable=True)\n",
    "if len(gpus) > 1:\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = f\"{len(gpus) - 1}\"\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17cc68dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "W, H, CH = 64, 64, 1\n",
    "\n",
    "\n",
    "def load_img(path, width=W):\n",
    "    img = cv2.imread(path.numpy().decode())[..., 0].astype(np.float32) / 255.\n",
    "    shape_dst = np.min(img.shape[:2])\n",
    "    oh = (img.shape[0] - shape_dst) // 2\n",
    "    ow = (img.shape[1] - shape_dst) // 2\n",
    "    center_square = np.array([width, width]) // 2\n",
    "    new_size = (width, width)\n",
    "\n",
    "    # cropping + resize\n",
    "    img = img[oh:oh + shape_dst, ow:ow + shape_dst]\n",
    "    img = np.expand_dims(cv2.resize(img, new_size), -1)\n",
    "    return tf.constant(img)\n",
    "\n",
    "\n",
    "SUFFIX = '.JPG'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c748cf71",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "WAYS = 3\n",
    "SHOTS = 5\n",
    "QUERIES = 1\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "np.random.seed(2021)\n",
    "tf.random.set_seed(2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d873c631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source: 300\n"
     ]
    }
   ],
   "source": [
    "\n",
    "DATA_ROOT=\"./kaggle_fungi/source\"\n",
    "# DATA_ROOT=join(\"..\",\"..\",\"data\")\n",
    "# DATA_ROOT=\"I:\\AIA Small Data\\datasets\"\n",
    "source_classes = glob(join(DATA_ROOT,\"source\",\"*\"))\n",
    "# source_classes,target_classes=train_test_split(all_classes,test_size=0.2)\n",
    "sorce_len=len(source_classes)\n",
    "# target_len=len(target_classes)\n",
    "# print(f\"total {len(all_classes)} classes=source {sorce_len} + target {target_len} classes\")\n",
    "print(f\"source: {sorce_len}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6092e339",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 建立每個人的loader，隨意從每個人的圖片中抽取 (尚未指定張數)\n",
    "# '''Mapping function for loading'''\n",
    "map_fun = lambda string: tf.py_function(func=load_img, inp=[string], Tout=tf.float32)\n",
    "# '''Source set中每個人都有一個tf Dataset loader'''\n",
    "source_sup_sub = [\n",
    "    tf.data.Dataset.list_files(glob(join(sc, '*' + SUFFIX)), shuffle=True)\n",
    "        .map(map_fun).cache()\n",
    "    for sc in source_classes\n",
    "]\n",
    "\n",
    "# **將所有可能run過一遍，讓cache記得**\n",
    "for sub in source_sup_sub:\n",
    "    for x in iter(sub.batch(10)):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09676dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 建立每個task的loader，隨意從WAY個人抽取SHOT張，並再隨機指派每個way的class是從0~WAY-1的哪一個\n",
    "def gen(all_sub):\n",
    "    order = np.random.permutation(len(all_sub))\n",
    "    '''For each task'''\n",
    "    for tasks in range(len(all_sub) // WAYS):\n",
    "        '''從已決定好的順序拉出WAY個人'''\n",
    "        picked = [all_sub[tt] for tt in order[WAYS * tasks:WAYS * (tasks + 1)]]\n",
    "        '''support每個人各有SHOTS張照片'''\n",
    "        support = tf.concat(\n",
    "            [\n",
    "                next(\n",
    "                    iter(\n",
    "                        sub.batch(SHOTS)\n",
    "                    )\n",
    "                ) for sub in picked\n",
    "            ]\n",
    "            , axis=0)\n",
    "        '''query挑WAY人中的QUERY張，這邊是設定每張屬於不同人，順序不固定'''\n",
    "        idxs = np.random.choice(range(WAYS), size=QUERIES, replace=False)\n",
    "        query = tf.concat(\n",
    "            [\n",
    "                next(\n",
    "                    iter(\n",
    "                        picked[idx].batch(1)\n",
    "                    )\n",
    "                ) for idx in idxs\n",
    "            ]\n",
    "            , axis=0)\n",
    "        '''輸出的時候把support跟query接在一起'''\n",
    "        yield tf.concat([support, query], axis=0), \\\n",
    "              tf.stack([keras.utils.to_categorical(idx, num_classes=WAYS) for idx in idxs], axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "84563b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def gen_test():\n",
    "    # # 歷遍test 資料 (2200)\n",
    "    for i in range(len(df)):\n",
    "        # 每一筆test 有 三個類別\n",
    "        print(f'test: {i}')\n",
    "        row_data = df.iloc[i]\n",
    "        ts_sup_sub = []\n",
    "        for index, k in enumerate(['support_0', 'support_1', 'support_2']):\n",
    "            md = tf.data.Dataset.list_files(\n",
    "                glob(join('target_s', row_data[k], '*' + SUFFIX)), shuffle=True).map(map_fun).cache()\n",
    "            ts_sup_sub.append(md)\n",
    "\n",
    "        ts_target_sub = tf.data.Dataset.list_files(\n",
    "            os.path.join('target_q', row_data['filename'])).map(map_fun)\n",
    "\n",
    "        for sub in ts_sup_sub:\n",
    "            for x in iter(sub.batch(5)):\n",
    "                pass\n",
    "        # # Support\n",
    "        data = []\n",
    "        for sub in ts_sup_sub:\n",
    "            data.append(next(iter(sub.batch(SHOTS))))\n",
    "        support = tf.concat(data, axis=0)\n",
    "        # Query\n",
    "        query = next(iter(ts_target_sub.batch(SHOTS)))\n",
    "        yield tf.concat([support, query], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31dc0324",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 建立data generator，可以一次抽一個meta batch的資料\n",
    "# 1. 要input一個function(這邊用partial產生一個預先設定好參數的function)\n",
    "# 1. output types要對好前面的格式\n",
    "# 2. output shape要給對\n",
    "\n",
    "MLUT = 16\n",
    "data_source = tf.data.Dataset.from_generator(\n",
    "    partial(gen, source_sup_sub),\n",
    "    output_types=(tf.float32, tf.float32),\n",
    "    output_shapes=((WAYS * SHOTS + QUERIES, W, H, CH), (QUERIES, WAYS))\n",
    ").repeat(MLUT).shuffle(buffer_size=999).cache().batch(BATCH_SIZE).prefetch(MLUT)\n",
    "\n",
    "\n",
    "data_target = tf.data.Dataset.from_generator(\n",
    "    gen_test,\n",
    "    output_types=(tf.float32),\n",
    "    output_shapes=(WAYS * SHOTS + QUERIES, W, H, CH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba81fbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_net(input_shape):\n",
    "    convnet = Sequential()\n",
    "    for i in range(3):\n",
    "        convnet.add(Conv2D(64, (3, 3), padding='valid', input_shape=input_shape))\n",
    "        convnet.add(BatchNormalization())\n",
    "        convnet.add(Activation('relu'))\n",
    "        convnet.add(MaxPooling2D())\n",
    "    return convnet\n",
    "\n",
    "\n",
    "def build_relation_network(input_shape):\n",
    "    seq = Sequential()\n",
    "    # layer1\n",
    "    seq.add(Conv2D(64, kernel_size=3, input_shape=input_shape,\n",
    "                   padding=\"valid\", activation='relu'))\n",
    "    seq.add(BatchNormalization())\n",
    "    seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    #     seq.add(Dropout(.1))\n",
    "\n",
    "    seq.add(Flatten())\n",
    "    seq.add(Dense(8, activation='relu'))\n",
    "    #     seq.add(Dropout(0.1))\n",
    "    seq.add(Dense(1, activation=None))\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0279535",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dim = (W, H, CH)\n",
    "base_network = conv_net(base_dim)\n",
    "# Query feature\n",
    "x_in = Input(shape=(WAYS * SHOTS + QUERIES, W, H, CH))\n",
    "latent_s = [base_network(x_in[:, ii]) for ii in range(WAYS * SHOTS)]\n",
    "latent_q = [base_network(x_in[:, WAYS * SHOTS + ii]) for ii in range(QUERIES)]\n",
    "\n",
    "relation_net = build_relation_network((latent_q[0].shape[-3], latent_q[0].shape[-2], latent_q[0].shape[-1] * 2))\n",
    "\n",
    "y = []\n",
    "for q in latent_q:\n",
    "    relation_score = []\n",
    "    for ww in range(WAYS):\n",
    "        relation = [relation_net(tf.concat([q, s], -1)) for s in latent_s[ww * SHOTS:(ww + 1) * SHOTS]]\n",
    "        relation_score.append(tf.reduce_mean(tf.concat(relation, -1), -1, keepdims=True))\n",
    "\n",
    "    y.append(tf.nn.softmax(tf.concat(relation_score, -1), -1))\n",
    "pred = tf.stack(y, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0869af03",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = Model(inputs=x_in, outputs=pred)\n",
    "\n",
    "lr = 0.001\n",
    "reduce_lr = cb.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=6, min_lr=1e-8, verbose=1)\n",
    "tensorboard = cb.TensorBoard(log_dir=\"tf_relation_logs\")\n",
    "earlystop = cb.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True, verbose=1)\n",
    "opt = tf.keras.optimizers.Adam(lr=lr)\n",
    "model.compile(loss=CategoricalCrossentropy(), optimizer=opt, metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "92439388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "      2/Unknown - 0s 156ms/step - loss: 5.1537e-04 - acc: 1.0000WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0300s vs `on_train_batch_end` time: 0.2809s). Check your callbacks.\n",
      "200/200 [==============================] - 12s 61ms/step - loss: 7.1368e-04 - acc: 1.0000 - val_loss: 0.0055 - val_acc: 0.9994\n",
      "Epoch 2/20\n",
      "200/200 [==============================] - 12s 59ms/step - loss: 4.9639e-04 - acc: 1.0000 - val_loss: 0.0046 - val_acc: 1.0000\n",
      "Epoch 3/20\n",
      "200/200 [==============================] - 12s 59ms/step - loss: 3.6796e-04 - acc: 1.0000 - val_loss: 0.0039 - val_acc: 1.0000\n",
      "Epoch 4/20\n",
      "200/200 [==============================] - 12s 59ms/step - loss: 2.8373e-04 - acc: 1.0000 - val_loss: 0.0034 - val_acc: 1.0000\n",
      "Epoch 5/20\n",
      "200/200 [==============================] - 12s 60ms/step - loss: 2.2395e-04 - acc: 1.0000 - val_loss: 0.0031 - val_acc: 1.0000\n",
      "Epoch 6/20\n",
      "200/200 [==============================] - 12s 60ms/step - loss: 1.7956e-04 - acc: 1.0000 - val_loss: 0.0028 - val_acc: 1.0000\n",
      "Epoch 7/20\n",
      "200/200 [==============================] - 12s 60ms/step - loss: 1.4596e-04 - acc: 1.0000 - val_loss: 0.0025 - val_acc: 1.0000\n",
      "Epoch 8/20\n",
      "200/200 [==============================] - 12s 59ms/step - loss: 1.2027e-04 - acc: 1.0000 - val_loss: 0.0023 - val_acc: 1.0000\n",
      "Epoch 9/20\n",
      "200/200 [==============================] - 12s 59ms/step - loss: 1.0051e-04 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 10/20\n",
      "200/200 [==============================] - 12s 60ms/step - loss: 8.4748e-05 - acc: 1.0000 - val_loss: 0.0019 - val_acc: 1.0000\n",
      "Epoch 11/20\n",
      "200/200 [==============================] - 12s 59ms/step - loss: 7.2015e-05 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "Epoch 12/20\n",
      "200/200 [==============================] - 12s 60ms/step - loss: 6.1531e-05 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 13/20\n",
      "200/200 [==============================] - 12s 59ms/step - loss: 5.2845e-05 - acc: 1.0000 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 14/20\n",
      "200/200 [==============================] - 12s 60ms/step - loss: 4.5605e-05 - acc: 1.0000 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 15/20\n",
      "200/200 [==============================] - 12s 60ms/step - loss: 3.9461e-05 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 16/20\n",
      "200/200 [==============================] - 12s 60ms/step - loss: 3.4279e-05 - acc: 1.0000 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 17/20\n",
      "200/200 [==============================] - 12s 59ms/step - loss: 2.9854e-05 - acc: 1.0000 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 18/20\n",
      "200/200 [==============================] - 12s 59ms/step - loss: 2.6060e-05 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 19/20\n",
      "200/200 [==============================] - 12s 59ms/step - loss: 2.2803e-05 - acc: 1.0000 - val_loss: 0.0010 - val_acc: 1.0000\n",
      "Epoch 20/20\n",
      "200/200 [==============================] - 12s 59ms/step - loss: 1.9983e-05 - acc: 1.0000 - val_loss: 9.4768e-04 - val_acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "EPOCHS = 20  # 400\n",
    "try:\n",
    "    model.fit(data_source,\n",
    "              epochs=EPOCHS, verbose=1, workers=4,\n",
    "              callbacks=[reduce_lr, earlystop, tensorboard],\n",
    "              validation_data=data_source)\n",
    "except KeyboardInterrupt:\n",
    "    print(\"KeyboardInterrupt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "60a3d008",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>support_0</th>\n",
       "      <th>support_1</th>\n",
       "      <th>support_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TS2013PIC17437389.JPG</td>\n",
       "      <td>10000_Abortiporus_biennis</td>\n",
       "      <td>15888_Lactarius_pallidus</td>\n",
       "      <td>10065_Agaricus_campestris</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TS2010PIC72338205.JPG</td>\n",
       "      <td>10994_Basidioradulum_radula</td>\n",
       "      <td>15888_Lactarius_pallidus</td>\n",
       "      <td>11085_Xerocomellus_porosporus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TS2016-9169441_H1qNFt0u.JPG</td>\n",
       "      <td>11086_Xerocomellus_pruinatus</td>\n",
       "      <td>11095_Hortiboletus_rubellus</td>\n",
       "      <td>15888_Lactarius_pallidus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MC2017-9207438_B1nMv9EFW.JPG</td>\n",
       "      <td>11202_Buglossoporus_quercinus</td>\n",
       "      <td>11234_Calocera_viscosa</td>\n",
       "      <td>15888_Lactarius_pallidus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MAV2017-9203941_HkwZOvmuZ.JPG</td>\n",
       "      <td>11384_Ceratiomyxa_fruticulosa</td>\n",
       "      <td>15888_Lactarius_pallidus</td>\n",
       "      <td>11573_Chalciporus_piperatus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2195</th>\n",
       "      <td>MC2017-9216120_B1rV9k4oW.JPG</td>\n",
       "      <td>21155_Tricholoma_ustale</td>\n",
       "      <td>14667_Hericium_coralloides</td>\n",
       "      <td>14778_Hydnellum_concrescens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2196</th>\n",
       "      <td>EAT2017-9205185_BklapgTOOW.JPG</td>\n",
       "      <td>21155_Tricholoma_ustale</td>\n",
       "      <td>14799_Hydnum_rufescens</td>\n",
       "      <td>14815_Hygrocybe_acutoconica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2197</th>\n",
       "      <td>BWP2012PIC41205195.JPG</td>\n",
       "      <td>14849_Gliophorus_laetus</td>\n",
       "      <td>14845_Hygrocybe_insipida</td>\n",
       "      <td>21155_Tricholoma_ustale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2198</th>\n",
       "      <td>TRL2015PIC35525891.JPG</td>\n",
       "      <td>14863_Hygrocybe_punicea</td>\n",
       "      <td>21155_Tricholoma_ustale</td>\n",
       "      <td>14859_Cuphophyllus_pratensis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2199</th>\n",
       "      <td>TBE2017-9227098_rkfuS2R1pb.JPG</td>\n",
       "      <td>21155_Tricholoma_ustale</td>\n",
       "      <td>14886_Hygrophoropsis_aurantiaca</td>\n",
       "      <td>14866_Hygrocybe_reidii</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2200 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            filename                      support_0  \\\n",
       "0              TS2013PIC17437389.JPG      10000_Abortiporus_biennis   \n",
       "1              TS2010PIC72338205.JPG    10994_Basidioradulum_radula   \n",
       "2        TS2016-9169441_H1qNFt0u.JPG   11086_Xerocomellus_pruinatus   \n",
       "3       MC2017-9207438_B1nMv9EFW.JPG  11202_Buglossoporus_quercinus   \n",
       "4      MAV2017-9203941_HkwZOvmuZ.JPG  11384_Ceratiomyxa_fruticulosa   \n",
       "...                              ...                            ...   \n",
       "2195    MC2017-9216120_B1rV9k4oW.JPG        21155_Tricholoma_ustale   \n",
       "2196  EAT2017-9205185_BklapgTOOW.JPG        21155_Tricholoma_ustale   \n",
       "2197          BWP2012PIC41205195.JPG        14849_Gliophorus_laetus   \n",
       "2198          TRL2015PIC35525891.JPG        14863_Hygrocybe_punicea   \n",
       "2199  TBE2017-9227098_rkfuS2R1pb.JPG        21155_Tricholoma_ustale   \n",
       "\n",
       "                            support_1                      support_2  \n",
       "0            15888_Lactarius_pallidus      10065_Agaricus_campestris  \n",
       "1            15888_Lactarius_pallidus  11085_Xerocomellus_porosporus  \n",
       "2         11095_Hortiboletus_rubellus       15888_Lactarius_pallidus  \n",
       "3              11234_Calocera_viscosa       15888_Lactarius_pallidus  \n",
       "4            15888_Lactarius_pallidus    11573_Chalciporus_piperatus  \n",
       "...                               ...                            ...  \n",
       "2195       14667_Hericium_coralloides    14778_Hydnellum_concrescens  \n",
       "2196           14799_Hydnum_rufescens    14815_Hygrocybe_acutoconica  \n",
       "2197         14845_Hygrocybe_insipida        21155_Tricholoma_ustale  \n",
       "2198          21155_Tricholoma_ustale   14859_Cuphophyllus_pratensis  \n",
       "2199  14886_Hygrophoropsis_aurantiaca         14866_Hygrocybe_reidii  \n",
       "\n",
       "[2200 rows x 4 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv('./kaggle_fungi/test2.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "03ac948c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test: 0\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "InvalidArgumentError: Expected 'tf.Tensor(False, shape=(), dtype=bool)' to be true. Summarized data: b'No files matched pattern: '\nTraceback (most recent call last):\n\n  File \"C:\\ProgramData\\Anaconda3\\envs\\AIA_Small_Data\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 244, in __call__\n    ret = func(*args)\n\n  File \"C:\\ProgramData\\Anaconda3\\envs\\AIA_Small_Data\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 302, in wrapper\n    return func(*args, **kwargs)\n\n  File \"C:\\ProgramData\\Anaconda3\\envs\\AIA_Small_Data\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 827, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"<ipython-input-7-904c860548b0>\", line 10, in gen_test\n    glob(join('target_s', row_data[k], '*' + SUFFIX)), shuffle=True).map(map_fun).cache()\n\n  File \"C:\\ProgramData\\Anaconda3\\envs\\AIA_Small_Data\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 1115, in list_files\n    condition, [message], summarize=1, name=\"assert_not_empty\")\n\n  File \"C:\\ProgramData\\Anaconda3\\envs\\AIA_Small_Data\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\", line 201, in wrapper\n    return target(*args, **kwargs)\n\n  File \"C:\\ProgramData\\Anaconda3\\envs\\AIA_Small_Data\\lib\\site-packages\\tensorflow\\python\\util\\tf_should_use.py\", line 247, in wrapped\n    return _add_should_use_warning(fn(*args, **kwargs),\n\n  File \"C:\\ProgramData\\Anaconda3\\envs\\AIA_Small_Data\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\", line 158, in Assert\n    (condition, \"\\n\".join(data_str)))\n\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Expected 'tf.Tensor(False, shape=(), dtype=bool)' to be true. Summarized data: b'No files matched pattern: '\n\n\n\t [[{{node PyFunc}}]]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\AIA_Small_Data\\lib\\site-packages\\tensorflow\\python\\eager\\context.py\u001b[0m in \u001b[0;36mexecution_mode\u001b[1;34m(mode)\u001b[0m\n\u001b[0;32m   2101\u001b[0m       \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecutor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecutor_new\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2102\u001b[1;33m       \u001b[1;32myield\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2103\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\AIA_Small_Data\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    757\u001b[0m             \u001b[0moutput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 758\u001b[1;33m             output_shapes=self._flat_output_shapes)\n\u001b[0m\u001b[0;32m    759\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\AIA_Small_Data\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py\u001b[0m in \u001b[0;36miterator_get_next\u001b[1;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[0;32m   2609\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2610\u001b[1;33m       \u001b[0m_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2611\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\AIA_Small_Data\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   6842\u001b[0m   \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6843\u001b[1;33m   \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6844\u001b[0m   \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\AIA_Small_Data\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mUnknownError\u001b[0m: InvalidArgumentError: Expected 'tf.Tensor(False, shape=(), dtype=bool)' to be true. Summarized data: b'No files matched pattern: '\nTraceback (most recent call last):\n\n  File \"C:\\ProgramData\\Anaconda3\\envs\\AIA_Small_Data\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 244, in __call__\n    ret = func(*args)\n\n  File \"C:\\ProgramData\\Anaconda3\\envs\\AIA_Small_Data\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 302, in wrapper\n    return func(*args, **kwargs)\n\n  File \"C:\\ProgramData\\Anaconda3\\envs\\AIA_Small_Data\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 827, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"<ipython-input-7-904c860548b0>\", line 10, in gen_test\n    glob(join('target_s', row_data[k], '*' + SUFFIX)), shuffle=True).map(map_fun).cache()\n\n  File \"C:\\ProgramData\\Anaconda3\\envs\\AIA_Small_Data\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 1115, in list_files\n    condition, [message], summarize=1, name=\"assert_not_empty\")\n\n  File \"C:\\ProgramData\\Anaconda3\\envs\\AIA_Small_Data\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\", line 201, in wrapper\n    return target(*args, **kwargs)\n\n  File \"C:\\ProgramData\\Anaconda3\\envs\\AIA_Small_Data\\lib\\site-packages\\tensorflow\\python\\util\\tf_should_use.py\", line 247, in wrapped\n    return _add_should_use_warning(fn(*args, **kwargs),\n\n  File \"C:\\ProgramData\\Anaconda3\\envs\\AIA_Small_Data\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\", line 158, in Assert\n    (condition, \"\\n\".join(data_str)))\n\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Expected 'tf.Tensor(False, shape=(), dtype=bool)' to be true. Summarized data: b'No files matched pattern: '\n\n\n\t [[{{node PyFunc}}]] [Op:IteratorGetNext]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-eb9852fc61bf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# # 預測結果\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mall_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_target\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mpre\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\AIA_Small_Data\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    734\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    735\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# For Python 3 compatibility\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 736\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    737\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    738\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_next_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\AIA_Small_Data\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\u001b[0m in \u001b[0;36mnext\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    770\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    771\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 772\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    773\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    774\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\AIA_Small_Data\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    762\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_element_spec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_from_compatible_tensor_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    763\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 764\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mstructure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_compatible_tensor_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_element_spec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    765\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    766\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\AIA_Small_Data\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type, value, traceback)\u001b[0m\n\u001b[0;32m    128\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m                 \u001b[1;31m# Suppress StopIteration *unless* it's the same exception that\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\AIA_Small_Data\\lib\\site-packages\\tensorflow\\python\\eager\\context.py\u001b[0m in \u001b[0;36mexecution_mode\u001b[1;34m(mode)\u001b[0m\n\u001b[0;32m   2103\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2104\u001b[0m       \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecutor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecutor_old\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2105\u001b[1;33m       \u001b[0mexecutor_new\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\AIA_Small_Data\\lib\\site-packages\\tensorflow\\python\\eager\\executor.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     65\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[1;34m\"\"\"Waits for ops dispatched in this executor to finish.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m     \u001b[0mpywrap_tfe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTFE_ExecutorWaitForAllPendingNodes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mclear_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnknownError\u001b[0m: InvalidArgumentError: Expected 'tf.Tensor(False, shape=(), dtype=bool)' to be true. Summarized data: b'No files matched pattern: '\nTraceback (most recent call last):\n\n  File \"C:\\ProgramData\\Anaconda3\\envs\\AIA_Small_Data\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 244, in __call__\n    ret = func(*args)\n\n  File \"C:\\ProgramData\\Anaconda3\\envs\\AIA_Small_Data\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 302, in wrapper\n    return func(*args, **kwargs)\n\n  File \"C:\\ProgramData\\Anaconda3\\envs\\AIA_Small_Data\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 827, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"<ipython-input-7-904c860548b0>\", line 10, in gen_test\n    glob(join('target_s', row_data[k], '*' + SUFFIX)), shuffle=True).map(map_fun).cache()\n\n  File \"C:\\ProgramData\\Anaconda3\\envs\\AIA_Small_Data\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 1115, in list_files\n    condition, [message], summarize=1, name=\"assert_not_empty\")\n\n  File \"C:\\ProgramData\\Anaconda3\\envs\\AIA_Small_Data\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\", line 201, in wrapper\n    return target(*args, **kwargs)\n\n  File \"C:\\ProgramData\\Anaconda3\\envs\\AIA_Small_Data\\lib\\site-packages\\tensorflow\\python\\util\\tf_should_use.py\", line 247, in wrapped\n    return _add_should_use_warning(fn(*args, **kwargs),\n\n  File \"C:\\ProgramData\\Anaconda3\\envs\\AIA_Small_Data\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\", line 158, in Assert\n    (condition, \"\\n\".join(data_str)))\n\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Expected 'tf.Tensor(False, shape=(), dtype=bool)' to be true. Summarized data: b'No files matched pattern: '\n\n\n\t [[{{node PyFunc}}]]"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv('./kaggle_fungi/test2.csv')\n",
    "\n",
    "# # 預測結果\n",
    "all_result = []\n",
    "for batch in data_target.batch(50):\n",
    "    pre = model.predict(batch)\n",
    "    print(pre.shape)\n",
    "    for i in pre:\n",
    "        all_result.extend(np.argmax(i, axis=1))\n",
    "        print(allresult)\n",
    "# df = pd.read_csv('SampleSubmission2.csv')\n",
    "# df['ans'] = all_result\n",
    "# df.to_csv('Submission2.csv', index=False)\n",
    "# print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b531b1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4be7c96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3420a114",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
